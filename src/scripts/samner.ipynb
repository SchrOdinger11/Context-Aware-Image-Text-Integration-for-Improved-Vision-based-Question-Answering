{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhanshu/Desktop/UMASS_COURSES_SEMESTERS/SEM_2/NLP/Project/vqa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from models import NERModel, SamModelPrediction\n",
    "import json\n",
    "import cv2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "flan = NERModel(\"./fineTunedT5ForNER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(sentence):\n",
    "    instruction = f\" Extract exact words from the sentence that are either common nouns or proper noun from the sentence\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    1. Sentence: \"The cat sat on the mat?\" Common Nouns: cat, sat, mat.\n",
    "    2. Sentence: \"He drinks a lot of coffee and reads many books.\" Common Nouns:  coffee, reads, books.\n",
    "    3. Sentence: \"Sky is blue and grass is green.\" Common Nouns: sky, blue, grass, green.\n",
    "    4. Sentence: \"Is the  Boy is skateboarding on the wall?\" Common Nouns: boy, skateboarding, wall .\n",
    "    5. Sentence: \"What color is teddy bear \" Common Nouns: teddy bear, color\n",
    "    6. Sentence: \"Teddy bear is pink ?\" Common Nouns: teddy bear, pink\n",
    "    Sentence: \"{sentence}\"\n",
    "    Common Nouns:\"\"\"\n",
    "    # Encode the prompt\n",
    "    \n",
    "    \n",
    "    # Generate output\n",
    "    outputs = flan.extract_entities(instruction,prompt)\n",
    "    entity_list = [entity.strip() for entity in outputs.split(',')]\n",
    "    # Decode and process the output\n",
    "  \n",
    "   \n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Boys, skateboarding'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entities(\"Boys doing skateboarding behind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3588.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "Model loaded from /Users/sudhanshu/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/sudhanshu/Desktop/UMASS_COURSES_SEMESTERS/SEM_2/NLP/Project/dataset/combined_data.json'\n",
    "ner = NERModel()\n",
    "\n",
    "sam_predictor = SamModelPrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ner.extract_entities(\"Is TeddyBear pink?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.4765262, 'index': 2, 'word': 'Teddy', 'start': 3, 'end': 8}, {'entity': 'I-ORG', 'score': 0.8116944, 'index': 3, 'word': '##B', 'start': 8, 'end': 9}, {'entity': 'I-ORG', 'score': 0.7172411, 'index': 4, 'word': '##ear', 'start': 9, 'end': 12}]\n",
      "['Teddy', '##B', '##ear']\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "entities= getEntities(x)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-LOC', 'score': 0.6480648, 'index': 7, 'word': '##eric', 'start': 21, 'end': 25}]\n"
     ]
    }
   ],
   "source": [
    "x= ner.extract_entities(\"Apples are born in america\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/Users/sudhanshu/Desktop/UMASS_COURSES_SEMESTERS/SEM_2/NLP/Project/testSam.jpeg\"\n",
    "image=Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Use the predict_image method with the loaded image and a text prompt\n",
    "entities=[\"hello\",\"a\",\"0\"]\n",
    "masks = [sam_predictor.predict_image(image, ent) for ent in entities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    \"\"\"\n",
    "    Adds a mask to an existing Axes object with the option to use a random color.\n",
    "\n",
    "    Args:\n",
    "    mask (array): A 2D numpy array representing the mask.\n",
    "    ax (matplotlib.axes.Axes): The Axes object where the mask will be added.\n",
    "    random_color (bool): If True, the mask will be displayed in a random color.\n",
    "    \"\"\"\n",
    "    if random_color:\n",
    "        # Generate a random color with transparency\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        # Use a specific color with transparency\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "\n",
    "    h, w = mask.shape\n",
    "    # Multiply the mask by the color and reshape for proper display\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image, interpolation='none', alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmented_image(pil_image, masks, background_color=(0, 0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Create a segmented image where only the areas defined by masks are visible,\n",
    "    and the rest is set to a specified background color.\n",
    "\n",
    "    Args:\n",
    "    pil_image (PIL.Image): The original image.\n",
    "    masks (list of numpy arrays): A list of 2D numpy arrays representing masks.\n",
    "    background_color (tuple): RGBA color tuple for the background, defaults to transparent.\n",
    "\n",
    "    Returns:\n",
    "    PIL.Image: The segmented image with only masked areas from the original image.\n",
    "    \"\"\"\n",
    "    if  len(masks) ==0:  # Check if the masks list is empty\n",
    "        return pil_image\n",
    "    # Convert the PIL Image to a NumPy array (RGBA for transparency handling)\n",
    "    image_np = np.array(pil_image.convert('RGB'))\n",
    "\n",
    "    # Prepare a blank canvas for the final image with the background color\n",
    "    final_image_np = np.full(image_np.shape, background_color, dtype=np.uint8)\n",
    "\n",
    "    # Process each mask\n",
    "    for mask in masks:\n",
    "        # Apply the mask to copy relevant parts from the original image to the final image\n",
    "        final_image_np[mask] = image_np[mask]\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    segmented_image = Image.fromarray(final_image_np, 'RGB')\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mask=mask.numpy()\n",
    "# mask = torch.from_numpy(mask)\n",
    "print(type(masks))\n",
    "\n",
    "#masks = [item for sublist in masks for item in sublist]\n",
    "result_image = create_segmented_image(image, masks)\n",
    "directory = \"segmentedImage\"\n",
    "print(result_image.mode)\n",
    "filename=\"hola\"\n",
    "result_image.save(os.path.join(directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER and SAM applied on Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flanT5 = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
